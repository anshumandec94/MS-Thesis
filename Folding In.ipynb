{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lenskit import batch,topn\n",
    "from lenskit.metrics import topn as tn\n",
    "from lenskit.algorithms import als\n",
    "from lenskit.matrix import  CSR,RatingMatrix\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from lenskit import topn\n",
    "from IPython.core.debugger import set_trace\n",
    "from lenskit.metrics import predict\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Here we are importing the ratings data file and the truncated users ratings file( which consists of the ratings of our sampled casual users and their popular movie ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('/project/naray190/ml-20m/ratings.csv')\n",
    "test=pd.read_csv('/project/naray190/ml-20m/test_casual_user_ratings.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are renaming the columns of the data to match with the values used by the functions of the \"lenskit\" package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[['userId','movieId','rating']]\n",
    "test=test[['userId','movieId','rating']]\n",
    "train.columns = ['user','item','rating']\n",
    "test.columns=['user','item','rating']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating Normalization\n",
    "\n",
    "Here, we are normalizing the ratings of our data sets. We are removing both user biases and item biases from the two sets of ratings data that we have.\n",
    "We are normalizing our data because to implement our fold in function we need to create which overrides some of the functionality of the original matrix factorization class implemented in Lenskit. Overriding would be difficult without manually removing the biases and having two seperate user indexes which is tied into the biasing method implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbias=train['rating'].mean()\n",
    "train['rating']-=gbias\n",
    "test['rating']-=gbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group=train.groupby('item')['rating']\n",
    "item_biases=group.sum()/(group.count()+5)\n",
    "train=train.join(pd.DataFrame(item_biases),on=\"item\",how=\"inner\",rsuffix=\"_im\")\n",
    "train=train.assign(rating=lambda df:df.rating-df.rating_im)\n",
    "test=test.join(pd.DataFrame(item_biases),on=\"item\",how=\"inner\",rsuffix=\"_im\")\n",
    "test=test.assign(rating=lambda df:df.rating-df.rating_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group=train.groupby('user')['rating']\n",
    "user_biases_train=group.sum()/(group.count()+5)\n",
    "train=train.join(pd.DataFrame(user_biases_train),on=\"user\",how=\"inner\",rsuffix=\"_um\")\n",
    "train=train.assign(rating=lambda df:df.rating-df.rating_um)\n",
    "group=test.groupby('user')['rating']\n",
    "user_biases_test=group.sum()/(group.count()+5)\n",
    "test=test.join(pd.DataFrame(user_biases_test),on=\"user\",how=\"inner\",rsuffix=\"_um\")\n",
    "test=test.assign(rating=lambda df:df.rating-df.rating_um)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[['user','item','rating']]#cleaning up the columns, removing the extra columns we used to subtract the biases from the ratings.\n",
    "test=test[['user','item','rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folding-In Function\n",
    "\n",
    "Here we implement a fold-in function where we can pass a ratings matrix and it will help generate user feature vectors given the pre-existing model trained item feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldIn(als.BiasedMF):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super (FoldIn,self).__init__(*args,**kwargs)\n",
    "        self.bias=None\n",
    "    def fold_in(self,new_ratings):\n",
    "        #set_trace()\n",
    "        rmat, users, items = sparse_ratings(new_ratings,iidx=self.item_index_)\n",
    "        n_users = len(users)\n",
    "        n_items = len(items)\n",
    "        \n",
    "        \n",
    "        umat = np.full((n_users, self.features), np.nan)\n",
    "        #set_trace()\n",
    "        umat = als._train_matrix(rmat.N, self.item_features_, self.regularization)\n",
    "        #set_trace()\n",
    "\n",
    "        return umat,users\n",
    "    \n",
    "\n",
    "def sparse_ratings(ratings, scipy=False,uidx=None,iidx=None):\n",
    "    \"\"\"\n",
    "    Convert a rating table to a sparse matrix of ratings.\n",
    "    Args:\n",
    "        ratings(pandas.DataFrame): a data table of (user, item, rating) triples.\n",
    "        scipy: if ``True``, return a SciPy matrix instead of :py:class:`CSR`.\n",
    "    Returns:\n",
    "        RatingMatrix:\n",
    "            a named tuple containing the sparse matrix, user index, and item index.\n",
    "    \"\"\"\n",
    "    #set_trace()\n",
    "    if(uidx is None): \n",
    "        uidx = pd.Index(ratings.user.unique(), name='user')\n",
    "    if(iidx is None):\n",
    "        iidx = pd.Index(ratings.item.unique(), name='item')\n",
    "    \n",
    "\n",
    "    row_ind = uidx.get_indexer(ratings.user).astype(np.int32)\n",
    "    col_ind = iidx.get_indexer(ratings.item).astype(np.int32)\n",
    "\n",
    "    if 'rating' in ratings.columns:\n",
    "        vals = np.require(ratings.rating.values, np.float64)\n",
    "    else:\n",
    "        vals = None\n",
    "\n",
    "    matrix = CSR.from_coo(row_ind, col_ind, vals, (len(uidx), len(iidx)))\n",
    "    #set_trace()\n",
    "    if scipy:\n",
    "        matrix = CSR.to_scipy(matrix)\n",
    "\n",
    "    return RatingMatrix(matrix, uidx, iidx)\n",
    "\n",
    "algo=FoldIn(features=25,iterations=50,reg=0.1)#we are overwritng the model object with our own Fold-In object. \n",
    "algo.fit(train)\n",
    "regularumat=algo.user_features_\n",
    "poponlyumat,popuindex=algo.fold_in(test)# the folding_in function returns to us the user matrix for our sample users and a user index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users=set(train.user.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=set(test.user.unique())\n",
    "other_users= all_users-users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are calculating the average cosine similarity between two users who are not being tested. This is for a baseline when looking at the cosine similarity between the two profiles of our test users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product=0\n",
    "avgcos=0\n",
    "ux=algo.user_index_\n",
    "for i in range(10000):\n",
    "    luser=random.sample(other_users,2)\n",
    "    uix1=ux.get_loc(luser[0])\n",
    "    uix2=ux.get_loc(luser[1])\n",
    "    u1v=regularumat[uix1]\n",
    "    u2v=regularumat[uix2]\n",
    "    dot_product=1-spatial.distance.cosine(u1v,u2v)\n",
    "    avgcos+=dot_product\n",
    "print(avgcos/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Similarity and Baseline Pairwise Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testusers=test['user'].unique().tolist()\n",
    "user_simscore=pd.DataFrame(columns=['user','simscore'])\n",
    "r=0\n",
    "\n",
    "for user in testusers:\n",
    "    indexf = algo.user_index_.get_loc(user)\n",
    "    indexp= popuindex.get_loc(user)\n",
    "    full_v=regularumat[indexf]\n",
    "    pop_v=poponlyumat[indexp]\n",
    "    dot_product=1-spatial.distance.cosine(full_v,pop_v)\n",
    "    user_simscore.loc[r]=[user,dot_product]\n",
    "    r=r+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline pairwise similarity between the users of our test group. We look at the baseline similarity for both profiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_sim_score=0\n",
    "count=0\n",
    "for user1 in testusers:\n",
    "    \n",
    "    if testusers.index(user1) != len(testusers)-1:\n",
    "        user2=testusers[testusers.index(user1)+1]\n",
    "        ind1=algo.user_index_.get_loc(user1)\n",
    "        ind2=algo.user_index_.get_loc(user2)\n",
    "        u1v=regularumat[ind1]\n",
    "        u2v=regularumat[ind2]\n",
    "        dot_product=1-spatial.distance.cosine(u1v,u2v)\n",
    "        pairwise_sim_score+=dot_product\n",
    "        count+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_sim_score/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_sim_score_pop=0\n",
    "count=0\n",
    "for user1 in testusers:\n",
    "    \n",
    "    if testusers.index(user1) != len(testusers)-1:\n",
    "        user2=testusers[testusers.index(user1)+1]\n",
    "        ind1=popuindex.get_loc(user1)\n",
    "        ind2=popuindex.get_loc(user2)\n",
    "        u1v=poponlyumat[ind1]\n",
    "        u2v=poponlyumat[ind2]\n",
    "        dot_product=1-spatial.distance.cosine(u1v,u2v)\n",
    "        pairwise_sim_score_pop+=dot_product\n",
    "        count+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_sim_score_pop/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=test.user.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemmat=algo.item_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=pd.DataFrame(columns=['user','item','score','rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_predicts=pd.DataFrame(columns=['user','item','score','rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the items here\n",
    "\n",
    "The following function is used to find candidate items for our user, score the items, and rank them by the score, and return the top-k recommendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_for_users(algo,users,user_index,user_matrix,predicts,train,k):\n",
    "    for user in users:\n",
    "        uix=user_index.get_loc(user)\n",
    "        uvfull=user_matrix[uix]\n",
    "        user_movies=train.loc[train['user']==user]\n",
    "        movie_list=set(user_movies['item'].tolist())\n",
    "        candidates=set(train['item'].unique())-movie_list\n",
    "        remove_movie=set(movie_data.loc[movie_data[\"popularity\"]<10].item.values)\n",
    "        candidates=candidates-remove_movie\n",
    "        candidates=list(candidates)\n",
    "        iix=algo.lookup_items(candidates)\n",
    "    #for movie in candidates:\n",
    "        #iix=algo.item_index_.get_loc(movie)\n",
    "        score=np.matmul(algo.item_features_[iix],uvfull)\n",
    "        score=score+item_biases.loc[candidates]+user_biases_train[user]+gbias\n",
    "        scores=pd.DataFrame({\"item\":candidates,\"score\":score})\n",
    "        scores['user']=user\n",
    "        scores=scores.sort_values('score',ascending=False)\n",
    "        scores=scores.head(k)\n",
    "        scores['rank']=scores['score'].rank(ascending=0)\n",
    "        predicts=predicts.append(scores,sort=True)\n",
    "    return predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate recommendations for the two sets of profiles to compare the recommendations that the full profile and the popular only profile receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=recommend_for_users(algo,users,algo.user_index_,algo.user_features_,predicts,train,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_predicts=recommend_for_users(algo,users,popuindex,poponlyumat,predicts,train,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users=set(train.user.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other=all_users-set(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_users=random.sample(other,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ou_list=list(other_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_predicts=pd.DataFrame(columns=['user','item','score','rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_predicts=recommend_for_users(algo,ou_list,algo.user_index_,algo.user_features_,other_predicts,train,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap=0#calculating the average overlap between users in the test set\n",
    "for i in range(10000):\n",
    "    u=random.sample(users,2)\n",
    "    rec1=set(predicts.item.loc[predicts.user == u[0]])\n",
    "    rec2=set(predicts.item.loc[predicts.user == u[1]])\n",
    "    o=len(rec1.intersection(rec2))\n",
    "    overlap += o\n",
    "    \n",
    "overlap=overlap/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap=0# calculates the average overlap between recs generated for users outside of the test set.\n",
    "for i in range(10000):\n",
    "    u=random.sample(other_users,2)\n",
    "    rec1=set(other_predicts.item.loc[other_predicts.user == u[0]])\n",
    "    rec2=set(other_predicts.item.loc[other_predicts.user == u[1]])\n",
    "    o=len(rec1.intersection(rec2))\n",
    "    overlap += o\n",
    "\n",
    "    overlap=overlap/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users=random.sample(all_users,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxsimscores=[]# generates the average highest cosine similarity score a user gets for another user in the system. This \n",
    "                # is to provide some insight on the similarity scores we observe between two profiles of a user.\n",
    "for u1 in users:\n",
    "    maxscore=0;\n",
    "    for u2 in list(all_users):\n",
    "        if u2 != u1:\n",
    "            u1ix=algo.user_index_.get_loc(u1)\n",
    "            u2ix=algo.user_index_.get_loc(u2)\n",
    "            u1v=regularumat[u1ix]\n",
    "            u2v=regularumat[u2ix]\n",
    "            dot_product=1-spatial.distance.cosine(u1v,u2v)\n",
    "            if dot_product>maxscore:\n",
    "                maxscore=dot_product\n",
    "            \n",
    "        \n",
    "    maxsimscores.append(maxscore)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(maxsimscores)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts.to_csv(\"ALS25FT20RecsReg01fwithrank.tsv\",sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_predicts.to_csv(\"ALS25FT20RecsPopProfileReg01fwithrank.tsv\",sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data=pd.read_csv(\"/project/naray190/movie_data_20M.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data.columns=['item','popularity','avgRating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data=pd.read_csv(\"/project/naray190/user_data_20M.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.columns=['user','count','popcount','unpopcount','percentpop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are looking at the impressions(no of times being recommended overall) of the movies being recommended to the test set of users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_impressions=pd.DataFrame(columns=['item','impression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie=set()\n",
    "for index, row in predicts.iterrows():\n",
    "    \n",
    "    movie_id=row['item']\n",
    "    if(movie_id in movie):\n",
    "        mirow=movie_impressions.loc[movie_impressions['item'] == movie_id]\n",
    "        count=mirow['impression']+1\n",
    "        movie_impressions.impression.loc[movie_impressions['item'] ==  movie_id] = count\n",
    "    \n",
    "    else:\n",
    "        newrow=pd.DataFrame([[movie_id,1]], columns=['item','impression'])\n",
    "        movie.add(movie_id)    \n",
    "        movie_impressions=movie_impressions.append(newrow)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_movie_impressions=pd.DataFrame(columns=['item','impression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie=set()\n",
    "for index, row in pop_predicts.iterrows():\n",
    "    \n",
    "    movie_id=row['item']\n",
    "    if(movie_id in movie):\n",
    "        mirow=pop_movie_impressions.loc[pop_movie_impressions['item'] == movie_id]\n",
    "        count=mirow['impression']+1\n",
    "        pop_movie_impressions.impression.loc[pop_movie_impressions['item'] ==  movie_id] = count\n",
    "    \n",
    "    else:\n",
    "        newrow=pd.DataFrame([[movie_id,1]], columns=['item','impression'])\n",
    "        movie.add(movie_id)    \n",
    "        pop_movie_impressions=pop_movie_impressions.append(newrow)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_data=pd.merge(movie_impressions,movie_data,on=['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mov_data=pd.merge(pop_movie_impressions,movie_data,on=['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_data.loc[mov_data.popularity<20].sort_values(by=\"impression\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mov_data.loc[pop_mov_data.popularity<20].sort_values(by=\"popularity\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_data.to_csv(\"movie_recommendation_impressions_ALS25Freg01filtered.csv\",sep=\"\\t\",index=None)\n",
    "pop_mov_data.to_csv(\"movie_pop_recommendation_impressions_ALS25Freg01filtered.csv\",sep=\"\\t\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_movies=set(predicts['item'].unique())\n",
    "pop_pred_movies=set(pop_predicts['item'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the overlap between the recommendations received by a test user's full and popular only profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_overlap=pd.DataFrame(columns=[\"user\",\"overlap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for user in users:\n",
    "    frecs=set(predicts.item.loc[predicts.user == user])\n",
    "    precs=set(pop_predicts.item.loc[pop_predicts.user == user])\n",
    "    overlap=len(frecs.intersection(precs))\n",
    "    newrow=pd.DataFrame([[user,overlap]],columns=[\"user\",\"overlap\"])\n",
    "    user_overlap=user_overlap.append(newrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popIds=set(movie_data.item.loc[movie_data.popularity>1450])# extracting the movieId of the top 2500 movies in the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate a summary of the recommendation the test users receive. This includes how many of the movies are popular vs unpopular and the average score of the movies and the average rating of the movies being recommended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_full_recs_summary=pd.DataFrame(columns=[\"user\",\"popcount\",\"unpopcount\",\"avgscore\",\"avgrating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    \n",
    "    recs=predicts.loc[predicts.user == user]\n",
    "    recset=set(recs.item)\n",
    "    recpop=len(recs.loc[recs.item.isin(popIds)])\n",
    "    recunpop=20-recpop\n",
    "    recavgscore=recs.score.mean()\n",
    "    recavgrating=movie_data.avgRating.loc[movie_data.item.isin(recset)].mean()\n",
    "    newrow=pd.DataFrame([[user,recpop,recunpop,recavgscore,recavgrating]],columns=[\"user\",\"popcount\",\"unpopcount\",\"avgscore\",\"avgrating\"])\n",
    "    user_full_recs_summary=user_full_recs_summary.append(newrow)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_full_recs_summary.to_csv(\"ALS25Freg01recsummaryfull.csv\",sep=\",\",header=True,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pop_recs_summary=pd.DataFrame(columns=[\"user\",\"popcount\",\"unpopcount\",\"avgscore\",\"avgrating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    \n",
    "    recs=pop_predicts.loc[pop_predicts.user == user]\n",
    "    recset=set(recs.item)\n",
    "    recpop=len(recs.loc[recs.item.isin(popIds)])\n",
    "    recunpop=20-recpop\n",
    "    recavgscore=recs.score.mean()\n",
    "    recavgrating=movie_data.avgRating.loc[movie_data.item.isin(recset)].mean()\n",
    "    newrow=pd.DataFrame([[user,recpop,recunpop,recavgscore,recavgrating]],columns=[\"user\",\"popcount\",\"unpopcount\",\"avgscore\",\"avgrating\"])\n",
    "    user_pop_recs_summary=user_pop_recs_summary.append(newrow)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pop_recs_summary.to_csv(\"ALS25Freg01recssummarypop.csv\",sep=\",\",header=True,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are calculating the diversity of user recommendations, we do this by looking at how far apart the item feature vectors of the items being recommended to a user are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_diversity=pd.DataFrame(columns=['user','diversity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    rec_items=list(predicts.item.loc[predicts.user == user])\n",
    "    count=0\n",
    "    diversity=0\n",
    "    for item in rec_items:\n",
    "        if rec_items.index(item) < (len(rec_items)-1): \n",
    "            iix1=algo.item_index_.get_loc(item)\n",
    "            iix2=algo.item_index_.get_loc(rec_items[rec_items.index(item) + 1])\n",
    "            iu=algo.item_features_[iix1]\n",
    "            iv=algo.item_features_[iix2]\n",
    "            dot_product=spatial.distance.cosine(iu,iv)\n",
    "            diversity+=dot_product\n",
    "            count+=1\n",
    "    \n",
    "    diversity=diversity/count\n",
    "    newrow=pd.DataFrame([[user,diversity]],columns=['user','diversity'])\n",
    "    user_diversity=user_diversity.append(newrow)\n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_diversity_pop=pd.DataFrame(columns=['user','diversity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    rec_items=list(pop_predicts.item.loc[pop_predicts.user == user])\n",
    "    count=0\n",
    "    diversity=0\n",
    "    for item in rec_items:\n",
    "        if rec_items.index(item) < (len(rec_items)-1): \n",
    "            iix1=algo.item_index_.get_loc(item)\n",
    "            iix2=algo.item_index_.get_loc(rec_items[rec_items.index(item) + 1])\n",
    "            iu=algo.item_features_[iix1]\n",
    "            iv=algo.item_features_[iix2]\n",
    "            dot_product=spatial.distance.cosine(iu,iv)\n",
    "            diversity+=dot_product\n",
    "            count+=1\n",
    "    \n",
    "    diversity=diversity/count\n",
    "    newrow=pd.DataFrame([[user,diversity]],columns=['user','diversity'])\n",
    "    user_diversity_pop=user_diversity_pop.append(newrow)\n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells calculate the average diversity of all the movies that are recommended overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "diver=0\n",
    "pred_movie_list=list(predicts.item.unique())\n",
    "for movie in pred_movie_list:\n",
    "    if pred_movie_list.index(movie) < (len(pred_movie_list)-1):\n",
    "        iix1=algo.item_index_.get_loc(movie)\n",
    "        iix2=algo.item_index_.get_loc(pred_movie_list[pred_movie_list.index(movie) + 1])\n",
    "        iu=algo.item_features_[iix1]\n",
    "        iv=algo.item_features_[iix2]\n",
    "        dot_product=spatial.distance.cosine(iu,iv)\n",
    "        diver+=dot_product\n",
    "        count+=1\n",
    "print(diver/count)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "diver=0\n",
    "pred_movie_list=list(pop_predicts.item.unique())\n",
    "for movie in pred_movie_list:\n",
    "    if pred_movie_list.index(movie) < (len(pred_movie_list)-1):\n",
    "        iix1=algo.item_index_.get_loc(movie)\n",
    "        iix2=algo.item_index_.get_loc(pred_movie_list[pred_movie_list.index(movie) + 1])\n",
    "        iu=algo.item_features_[iix1]\n",
    "        iv=algo.item_features_[iix2]\n",
    "        dot_product=spatial.distance.cosine(iu,iv)\n",
    "        diver+=dot_product\n",
    "        count+=1\n",
    "print(diver/count)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now are looking at how personalized recommendations are. We get the top 20 most popular movies(which is what the most unpersonalized recommender who recommend) and look at the overlap between this top-20 and the top-20 recommended to a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies=movie_data.sort_values('popularity',ascending=False)\n",
    "top_movies=set(top_movies.head(20).item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalization_recs=pd.DataFrame(columns=['user','full','popularonly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    movlistf=set(predicts.loc[predicts['user']==user]['item'])\n",
    "    movlistp=set(pop_predicts.loc[pop_predicts['user']==user]['item'])\n",
    "    full=len(movlistf.intersection(top_movies))\n",
    "    popularonly=len(movlistp.intersection(top_movies))\n",
    "    newrow=pd.DataFrame([[user,full,popularonly]],columns=['user','full','popularonly'])\n",
    "    personalization_recs=personalization_recs.append(newrow)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalization_recs.to_csv('ALS25Fr01filteredfvsp.csv',sep=\",\",header=True,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_diversity_pop.to_csv(\"ALS25FReg01user_diversity_pop.csv\",sep=\",\",header=True,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_diversity.to_csv(\"ALS25FReg01user_diversity.csv\",sep=\",\",header=True,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_overlap.to_csv(\"ALS25Freg01filteredoverlap.csv\",sep=\",\",header=True,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts.to_csv('ALS_30F_recs_folding_in.tsv',sep='\\t',header=True,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_simscore.to_csv('user_simscore_folded_in_ALS_25reg01filtered.tsv',sep='\\t',header=True,index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
